// services/geminiService.js

const { GoogleGenerativeAI } = require("@google/generative-ai");
const Sensor = require("../models/sensor.model");

// Kh·ªüi t·∫°o Gemini
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// ƒê·ªãnh nghƒ©a tools (functions) cho Gemini
const tools = [
  {
    functionDeclarations: [
      // TOOL 1: L·∫•y data M·ªöI NH·∫§T (cho "hi·ªán t·∫°i", "b√¢y gi·ªù")
      {
        name: "getLatestSensorData",
        description: `L·∫•y d·ªØ li·ªáu C·∫¢M BI·∫æN M·ªöI NH·∫§T (real-time, hi·ªán t·∫°i).

S·ª¨ D·ª§NG TOOL N√ÄY KHI:
- User h·ªèi v·ªÅ "hi·ªán t·∫°i", "b√¢y gi·ªù", "l√∫c n√†y", "th·ªùi ƒëi·ªÉm n√†y"
- User mu·ªën bi·∫øt gi√° tr·ªã CH√çNH X√ÅC c·ªßa c·∫£m bi·∫øn t·∫°i th·ªùi ƒëi·ªÉm hi·ªán t·∫°i
- User h·ªèi "nhi·ªát ƒë·ªô/ƒë·ªô ·∫©m/CO2/CO/PM2.5 hi·ªán t·∫°i l√† bao nhi√™u?"

KH√îNG S·ª¨ D·ª§NG tool n√†y khi user h·ªèi v·ªÅ trung b√¨nh ho·∫∑c xu h∆∞·ªõng.

Tr·∫£ v·ªÅ: 1 record m·ªõi nh·∫•t t·ª´ database (kh√¥ng ph·∫£i trung b√¨nh).`,
        parameters: {
          type: "object",
          properties: {},
          required: [],
        },
      },

      // TOOL 2: T√≠nh TRUNG B√åNH (cho "h√¥m nay", "1 gi·ªù qua", "xu h∆∞·ªõng")
      {
        name: "getSensorAverages",
        description: `L·∫•y gi√° tr·ªã TRUNG B√åNH c·ªßa c√°c c·∫£m bi·∫øn trong kho·∫£ng th·ªùi gian.

S·ª¨ D·ª§NG TOOL N√ÄY KHI:
- User h·ªèi v·ªÅ "h√¥m nay", "24h qua", "1 gi·ªù qua", "tu·∫ßn n√†y"
- User mu·ªën bi·∫øt XU H∆Ø·ªöNG, TRUNG B√åNH, ho·∫∑c T·ªîNG QUAN
- User h·ªèi "ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ h√¥m nay th·∫ø n√†o?"
- User h·ªèi "nhi·ªát ƒë·ªô trung b√¨nh 24h qua"

KH√îNG S·ª¨ D·ª§NG tool n√†y khi user h·ªèi v·ªÅ "hi·ªán t·∫°i", "b√¢y gi·ªù".

C√ÅCH X√ÅC ƒê·ªäNH THAM S·ªê hours:
- "h√¥m nay", "24h qua" ‚Üí hours=24
- "1 gi·ªù qua", "gi·ªù v·ª´a r·ªìi" ‚Üí hours=1
- "3 gi·ªù qua" ‚Üí hours=3
- "tu·∫ßn n√†y", "7 ng√†y qua" ‚Üí hours=168
- "t·ªïng quan", kh√¥ng ƒë·ªÅ c·∫≠p th·ªùi gian ‚Üí kh√¥ng truy·ªÅn hours`,
        parameters: {
          type: "object",
          properties: {
            hours: {
              type: "number",
              description:
                "S·ªë gi·ªù mu·ªën l·∫•y d·ªØ li·ªáu trung b√¨nh. V√≠ d·ª•: 1, 3, 24, 168. N·∫øu kh√¥ng truy·ªÅn, s·∫Ω l·∫•y t·∫•t c·∫£ d·ªØ li·ªáu.",
            },
          },
          required: [],
        },
      },
    ],
  },
];

// H√†m th·ª±c thi tool (GI·ªêNG Y H·ªÜT H√ÄM CONTROLLER)
async function executeTool(functionName, args) {
  console.log(`Executing tool: ${functionName}`);
  console.log(`Arguments:`, args);

  try {
    // TOOL 1: L·∫•y data M·ªöI NH·∫§T
    if (functionName === "getLatestSensorData") {
      const latestData = await Sensor.findOne()
        .sort({ timestamp: -1 }) // ‚Üê S·∫Øp x·∫øp theo th·ªùi gian gi·∫£m d·∫ßn
        .limit(1)
        .lean();

      if (!latestData) {
        return {
          success: false,
          message: "No sensor data found",
          data: null,
        };
      }

      const formattedData = {
        temperature: parseFloat(latestData.temperature?.toFixed(2) || 0),
        humidity: parseFloat(latestData.humidity?.toFixed(2) || 0),
        co2: Math.round(latestData.co2 || 0),
        co: parseFloat(latestData.co?.toFixed(2) || 0),
        pm25: parseFloat(latestData.pm25?.toFixed(2) || 0),
        timestamp: latestData.timestamp,
      };

      console.log("Latest sensor data:", formattedData);

      return {
        success: true,
        message: "Latest sensor data retrieved",
        data: formattedData,
      };
    }

    // TOOL 2: T√≠nh TRUNG B√åNH (code c≈©)
    if (functionName === "getSensorAverages") {
      const hours = args.hours || null;

      const pipeline = [];

      if (hours) {
        const timeLimit = new Date(Date.now() - hours * 60 * 60 * 1000);
        pipeline.push({
          $match: {
            timestamp: { $gte: timeLimit },
          },
        });
        console.log(`Filtering data from last ${hours} hours`);
      }

      pipeline.push({
        $group: {
          _id: null,
          avgTemperature: { $avg: "$temperature" },
          avgHumidity: { $avg: "$humidity" },
          avgCO2: { $avg: "$co2" },
          avgCO: { $avg: "$co" },
          avgPM25: { $avg: "$pm25" },
          totalRecords: { $sum: 1 },
          oldestRecord: { $min: "$timestamp" },
          newestRecord: { $max: "$timestamp" },
        },
      });

      const averages = await Sensor.aggregate(pipeline);

      if (!averages || averages.length === 0) {
        return {
          success: false,
          message: "No sensor data found",
          data: {
            temperature: 0,
            humidity: 0,
            co2: 0,
            co: 0,
            pm25: 0,
            totalRecords: 0,
          },
        };
      }

      const result = averages[0];

      const formattedResult = {
        temperature: parseFloat(result.avgTemperature?.toFixed(2) || 0),
        humidity: parseFloat(result.avgHumidity?.toFixed(2) || 0),
        co2: Math.round(result.avgCO2 || 0),
        co: parseFloat(result.avgCO?.toFixed(2) || 0),
        pm25: parseFloat(result.avgPM25?.toFixed(2) || 0),
        totalRecords: result.totalRecords || 0,
        timeRange: {
          from: result.oldestRecord || null,
          to: result.newestRecord || null,
        },
      };

      console.log("Sensor averages:", formattedResult);

      return {
        success: true,
        message: hours
          ? `Sensor averages for last ${hours} hours`
          : "Sensor averages for all data",
        data: formattedResult,
      };
    }

    return {
      success: false,
      message: `Unknown tool: ${functionName}`,
    };
  } catch (error) {
    console.error(`Error executing tool ${functionName}:`, error);
    return {
      success: false,
      message: `Error: ${error.message}`,
    };
  }
}

// H√†m chat v·ªõi Gemini
async function chat(userMessage, conversationHistory = []) {
  try {
    console.log("\n========== GEMINI CHAT ==========");
    console.log("üë§ User:", userMessage);

    // D√πng gemini-2.5-flash (m·ªõi nh·∫•t, h·ªó tr·ª£ function calling)
    const model = genAI.getGenerativeModel({
      model: "gemini-2.5-flash",
      tools: tools,
    });

    // System instruction
    const systemPrompt = `B·∫°n l√† AI Assistant chuy√™n v·ªÅ ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠. 
B·∫°n c√≥ th·ªÉ:
1. Tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠
2. ƒê√°nh gi√° v√† ph√¢n t√≠ch d·ªØ li·ªáu c·∫£m bi·∫øn
3. ƒê∆∞a ra khuy·∫øn ngh·ªã d·ª±a tr√™n c√°c ch·ªâ s·ªë
4. Nh·∫≠n x√©t th·ªùi ti·∫øt d·ª±a tr√™n gi√° tr·ªã c·∫£m bi·∫øn

B·∫°n c√≥ 2 TOOLS:
1. getLatestSensorData: L·∫•y d·ªØ li·ªáu C·∫¢M BI·∫æN M·ªöI NH·∫§T (1 ƒëi·ªÉm ƒëo)
2. getSensorAverages: T√≠nh TRUNG B√åNH c√°c c·∫£m bi·∫øn trong kho·∫£ng th·ªùi gian

QUAN TR·ªåNG - Ch·ªçn tool ph√π h·ª£p:

D√πng getLatestSensorData khi user h·ªèi:
- "Nhi·ªát ƒë·ªô hi·ªán t·∫°i", "nhi·ªát ƒë·ªô b√¢y gi·ªù"
- "ƒê·ªô ·∫©m hi·ªán t·∫°i", "CO2 l√∫c n√†y"
- "Ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ l√∫c n√†y th·∫ø n√†o?"
- B·∫•t k·ª≥ c√¢u h·ªèi n√†o c√≥ t·ª´: "hi·ªán t·∫°i", "b√¢y gi·ªù", "l√∫c n√†y", "th·ªùi ƒëi·ªÉm n√†y"

D√πng getSensorAverages khi user h·ªèi:
- "Nhi·ªát ƒë·ªô h√¥m nay th·∫ø n√†o?" ‚Üí hours=24
- "Ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ 1 gi·ªù qua" ‚Üí hours=1
- "ƒê√°nh gi√° kh√¥ng kh√≠ tu·∫ßn n√†y" ‚Üí hours=168
- "Xu h∆∞·ªõng nhi·ªát ƒë·ªô", "trung b√¨nh", "t·ªïng quan"

Ng∆∞·ª°ng ƒë√°nh gi√°:
- Nhi·ªát ƒë·ªô: 18-25¬∞C l√† t·ªët
- ƒê·ªô ·∫©m: 40-60% l√† t·ªët
- CO2: <1000 ppm l√† t·ªët, 1000-2000 trung b√¨nh, >2000 k√©m
- CO: <9 ppm l√† t·ªët, 9-35 trung b√¨nh, >35 k√©m
- PM2.5: <12 Œºg/m¬≥ t·ªët, 12-35 trung b√¨nh, >35 k√©m

H√£y tr·∫£ l·ªùi b·∫±ng ng√¥n ng·ªØ theo truy v·∫•n ng∆∞·ªùi d√πng, ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu v√† th√¢n thi·ªán.`;

    // T·∫°o chat session v·ªõi system prompt
    const chatHistory = [
      {
        role: "user",
        parts: [{ text: systemPrompt }],
      },
      {
        role: "model",
        parts: [
          {
            text: "Ch√†o b·∫°n! T√¥i l√† AI Assistant chuy√™n v·ªÅ ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n ph√¢n t√≠ch d·ªØ li·ªáu c·∫£m bi·∫øn v√† ƒë∆∞a ra khuy·∫øn ngh·ªã c·∫£i thi·ªán kh√¥ng kh√≠. B·∫°n mu·ªën t√¥i gi√∫p g√¨?",
          },
        ],
      },
      ...conversationHistory,
    ];

    const chat = model.startChat({
      history: chatHistory,
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 500,
      },
    });

    // G·ª≠i message
    let result = await chat.sendMessage(userMessage);
    let response = result.response;

    console.log("Gemini response received");

    // Ki·ªÉm tra c√≥ function call kh√¥ng
    let functionCalls = response.functionCalls();

    if (functionCalls && functionCalls.length > 0) {
      console.log("Function calls detected:", functionCalls.length);

      const functionResponses = [];

      for (const call of functionCalls) {
        console.log(`Calling: ${call.name}`, call.args);

        const toolResult = await executeTool(call.name, call.args);

        functionResponses.push({
          functionResponse: {
            name: call.name,
            response: toolResult,
          },
        });
      }

      // G·ª≠i k·∫øt qu·∫£ tool v·ªÅ cho Gemini
      result = await chat.sendMessage(functionResponses);
      response = result.response;

      console.log("Gemini analyzed tool results");
    }

    // L·∫•y text response
    const text = response.text();
    console.log("Final response:", text.substring(0, 100) + "...");
    console.log("========================================\n");

    return {
      success: true,
      message: text,
      conversationHistory: await chat.getHistory(),
    };
  } catch (error) {
    console.error("Gemini chat error:", error);

    // X·ª≠ l√Ω c√°c lo·∫°i l·ªói
    let errorMessage =
      "Xin l·ªói, t√¥i g·∫∑p l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i.";

    if (error.status === 404) {
      console.error("Model kh√¥ng t·ªìn t·∫°i ho·∫∑c kh√¥ng h·ªó tr·ª£");
      errorMessage =
        "Xin l·ªói, AI model hi·ªán kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng th·ª≠ l·∫°i sau.";
    } else if (error.status === 429) {
      console.error("Quota exceeded");
      const retryAfter = error.errorDetails?.[2]?.retryDelay || "1 ph√∫t";
      console.log(`Retry after: ${retryAfter}`);
      errorMessage = `Xin l·ªói, h·ªá th·ªëng ƒëang qu√° t·∫£i. Vui l√≤ng th·ª≠ l·∫°i sau ${retryAfter}.`;
    } else if (error.status === 500) {
      console.error("Gemini server error");
      errorMessage = "Xin l·ªói, AI ƒëang g·∫∑p s·ª± c·ªë. Vui l√≤ng th·ª≠ l·∫°i sau.";
    } else if (error.status === 400) {
      console.error("Bad request:", error.message);
      errorMessage = "Xin l·ªói, y√™u c·∫ßu kh√¥ng h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i.";
    }

    return {
      success: false,
      error: error.message,
      message: errorMessage,
    };
  }
}

module.exports = {
  chat,
};
