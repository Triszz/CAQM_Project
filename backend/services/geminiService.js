// services/geminiService.js

const { GoogleGenerativeAI } = require("@google/generative-ai");
const Sensor = require("../models/sensor.model");

// ‚úÖ Kh·ªüi t·∫°o Gemini
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// ‚úÖ ƒê·ªãnh nghƒ©a tools (functions) cho Gemini
const tools = [
  {
    functionDeclarations: [
      {
        name: "getSensorAverages",
        description:
          "L·∫•y gi√° tr·ªã trung b√¨nh c·ªßa c√°c c·∫£m bi·∫øn ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ (nhi·ªát ƒë·ªô, ƒë·ªô ·∫©m, CO2, CO, PM2.5). S·ª≠ d·ª•ng khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ t√¨nh tr·∫°ng kh√¥ng kh√≠, ch·∫•t l∆∞·ª£ng m√¥i tr∆∞·ªùng, ho·∫∑c y√™u c·∫ßu ƒë√°nh gi√° kh√¥ng kh√≠.",
        parameters: {
          type: "object",
          properties: {
            hours: {
              type: "number",
              description:
                "S·ªë gi·ªù mu·ªën l·∫•y d·ªØ li·ªáu trung b√¨nh (v√≠ d·ª•: 1, 24, 168). N·∫øu kh√¥ng c√≥, s·∫Ω l·∫•y t·∫•t c·∫£ d·ªØ li·ªáu.",
            },
          },
          required: [],
        },
      },
    ],
  },
];

// ‚úÖ H√†m th·ª±c thi tool (GI·ªêNG Y H·ªÜT H√ÄM CONTROLLER)
async function executeTool(functionName, args) {
  console.log(`üîß Executing tool: ${functionName}`);
  console.log("üì• Arguments:", args);

  if (functionName === "getSensorAverages") {
    try {
      const hours = args.hours || null;

      // ‚úÖ Build aggregation pipeline
      let matchStage = {};
      if (hours) {
        const timeLimit = new Date(Date.now() - hours * 60 * 60 * 1000);
        matchStage = {
          timestamp: { $gte: timeLimit },
        };
        console.log(`üïí Filtering data from last ${hours} hours`);
      }

      const pipeline = [];

      // Th√™m match stage n·∫øu c√≥ filter th·ªùi gian
      if (Object.keys(matchStage).length > 0) {
        pipeline.push({ $match: matchStage });
      }

      // Group v√† t√≠nh average
      pipeline.push({
        $group: {
          _id: null,
          avgTemperature: { $avg: "$temperature" },
          avgHumidity: { $avg: "$humidity" },
          avgCO2: { $avg: "$co2" },
          avgCO: { $avg: "$co" },
          avgPM25: { $avg: "$pm25" },
          totalRecords: { $sum: 1 },
          oldestRecord: { $min: "$timestamp" },
          newestRecord: { $max: "$timestamp" },
        },
      });

      // ‚úÖ Execute aggregation
      const averages = await Sensor.aggregate(pipeline);

      if (!averages || averages.length === 0) {
        return {
          success: false,
          message: "Kh√¥ng c√≥ d·ªØ li·ªáu c·∫£m bi·∫øn",
          data: {
            temperature: 0,
            humidity: 0,
            co2: 0,
            co: 0,
            pm25: 0,
            totalRecords: 0,
          },
        };
      }

      const result = averages[0];

      // ‚úÖ Format k·∫øt qu·∫£
      const formattedResult = {
        temperature: parseFloat(result.avgTemperature?.toFixed(2) || 0),
        humidity: parseFloat(result.avgHumidity?.toFixed(2) || 0),
        co2: Math.round(result.avgCO2 || 0),
        co: parseFloat(result.avgCO?.toFixed(2) || 0),
        pm25: parseFloat(result.avgPM25?.toFixed(2) || 0),
        totalRecords: result.totalRecords || 0,
        timeRange: {
          from: result.oldestRecord || null,
          to: result.newestRecord || null,
        },
      };

      console.log("‚úÖ Sensor averages:", formattedResult);

      return {
        success: true,
        data: formattedResult,
      };
    } catch (error) {
      console.error("‚ùå Error in getSensorAverages:", error);
      return {
        success: false,
        error: error.message,
      };
    }
  }

  return {
    success: false,
    error: "Unknown function",
  };
}

// ‚úÖ H√†m chat v·ªõi Gemini
async function chat(userMessage, conversationHistory = []) {
  try {
    console.log("\n========== GEMINI CHAT ==========");
    console.log("üë§ User:", userMessage);

    // ‚úÖ D√πng gemini-2.5-flash (m·ªõi nh·∫•t, h·ªó tr·ª£ function calling)
    const model = genAI.getGenerativeModel({
      model: "gemini-2.5-flash", // ‚úÖ Ho·∫∑c "gemini-2.5-flash" n·∫øu c√≥
      tools: tools,
    });

    // ‚úÖ System instruction
    const systemPrompt = `B·∫°n l√† AI Assistant chuy√™n v·ªÅ ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠. 
B·∫°n c√≥ th·ªÉ:
1. Tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠
2. ƒê√°nh gi√° v√† ph√¢n t√≠ch d·ªØ li·ªáu c·∫£m bi·∫øn
3. ƒê∆∞a ra khuy·∫øn ngh·ªã d·ª±a tr√™n c√°c ch·ªâ s·ªë
4. Nh·∫≠n x√©t th·ªùi ti·∫øt d·ª±a tr√™n gi√° tr·ªã c·∫£m bi·∫øn

Ng∆∞·ª°ng ƒë√°nh gi√°:
- Nhi·ªát ƒë·ªô: 18-25¬∞C l√† t·ªët
- ƒê·ªô ·∫©m: 40-60% l√† t·ªët
- CO2: <1000 ppm l√† t·ªët, 1000-2000 trung b√¨nh, >2000 k√©m
- CO: <9 ppm l√† t·ªët, 9-35 trung b√¨nh, >35 k√©m
- PM2.5: <12 Œºg/m¬≥ t·ªët, 12-35 trung b√¨nh, >35 k√©m

H√£y tr·∫£ l·ªùi b·∫±ng ng√¥n ng·ªØ theo truy v·∫•n ng∆∞·ªùi d√πng, ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu v√† th√¢n thi·ªán.`;

    // ‚úÖ T·∫°o chat session v·ªõi system prompt
    const chatHistory = [
      {
        role: "user",
        parts: [{ text: systemPrompt }],
      },
      {
        role: "model",
        parts: [
          {
            text: "Ch√†o b·∫°n! T√¥i l√† AI Assistant chuy√™n v·ªÅ ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n ph√¢n t√≠ch d·ªØ li·ªáu c·∫£m bi·∫øn v√† ƒë∆∞a ra khuy·∫øn ngh·ªã c·∫£i thi·ªán kh√¥ng kh√≠. B·∫°n mu·ªën t√¥i gi√∫p g√¨?",
          },
        ],
      },
      ...conversationHistory,
    ];

    const chat = model.startChat({
      history: chatHistory,
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 500,
      },
    });

    // ‚úÖ G·ª≠i message
    let result = await chat.sendMessage(userMessage);
    let response = result.response;

    console.log("ü§ñ Gemini response received");

    // ‚úÖ Ki·ªÉm tra c√≥ function call kh√¥ng
    let functionCalls = response.functionCalls();

    if (functionCalls && functionCalls.length > 0) {
      console.log("üîß Function calls detected:", functionCalls.length);

      const functionResponses = [];

      for (const call of functionCalls) {
        console.log(`üìû Calling: ${call.name}`, call.args);

        const toolResult = await executeTool(call.name, call.args);

        functionResponses.push({
          functionResponse: {
            name: call.name,
            response: toolResult,
          },
        });
      }

      // ‚úÖ G·ª≠i k·∫øt qu·∫£ tool v·ªÅ cho Gemini
      result = await chat.sendMessage(functionResponses);
      response = result.response;

      console.log("‚úÖ Gemini analyzed tool results");
    }

    // ‚úÖ L·∫•y text response
    const text = response.text();
    console.log("ü§ñ Final response:", text.substring(0, 100) + "...");
    console.log("========================================\n");

    return {
      success: true,
      message: text,
      conversationHistory: await chat.getHistory(),
    };
  } catch (error) {
    console.error("‚ùå Gemini chat error:", error);

    // ‚úÖ X·ª≠ l√Ω c√°c lo·∫°i l·ªói
    let errorMessage =
      "Xin l·ªói, t√¥i g·∫∑p l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i.";

    if (error.status === 404) {
      console.error("üí° Model kh√¥ng t·ªìn t·∫°i ho·∫∑c kh√¥ng h·ªó tr·ª£");
      errorMessage =
        "Xin l·ªói, AI model hi·ªán kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng th·ª≠ l·∫°i sau.";
    } else if (error.status === 429) {
      console.error("üí° Quota exceeded");
      const retryAfter = error.errorDetails?.[2]?.retryDelay || "1 ph√∫t";
      console.log(`‚è≥ Retry after: ${retryAfter}`);
      errorMessage = `Xin l·ªói, h·ªá th·ªëng ƒëang qu√° t·∫£i. Vui l√≤ng th·ª≠ l·∫°i sau ${retryAfter}.`;
    } else if (error.status === 500) {
      console.error("üí° Gemini server error");
      errorMessage = "Xin l·ªói, AI ƒëang g·∫∑p s·ª± c·ªë. Vui l√≤ng th·ª≠ l·∫°i sau.";
    } else if (error.status === 400) {
      console.error("üí° Bad request:", error.message);
      errorMessage = "Xin l·ªói, y√™u c·∫ßu kh√¥ng h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i.";
    }

    return {
      success: false,
      error: error.message,
      message: errorMessage,
    };
  }
}

module.exports = {
  chat,
};
